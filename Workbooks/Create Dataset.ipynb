{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b621359",
   "metadata": {},
   "source": [
    "# Create Dataset from Raw Data\n",
    "\n",
    "Please note, the original data and cell output in this workbook is not shared due to privacy. The original excel workbook is messy: full of typos, wrong data types, two data points in a cell. \n",
    "\n",
    "This workbook cleans the data up before creating a new data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f26d2-f9c3-4f04-ae82-c7f05a4b06a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac870dae-d544-4315-b64b-e61750a85ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and check\n",
    "\n",
    "df_first_tab = pd.read_excel(\"../Data/raw_data.xlsx\", sheet_name=0, usecols=[\"Date\",\"Time\",\"Bottle (ml)\",\"Poo\",\"Wee\",\"Other\"], nrows=237)\n",
    "\n",
    "df_first_tab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75f4dc9-9205-4218-9fa4-88e5b041fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and check - data exists on a second worksheet as well\n",
    "\n",
    "df_second_tab = pd.read_excel(\"../Data/raw_data.xlsx\", sheet_name=1, parse_dates=False)\n",
    "\n",
    "df_second_tab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f107cf-7f1b-4f29-8ffb-9961cd5ed8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine both worksheets to one dataframe\n",
    "\n",
    "df = pd.concat([df_first_tab, df_second_tab], ignore_index=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d33e49-0e1c-4888-b943-9959c1a09a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6efe6d-a3f9-4d86-92bd-54c27972a196",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Date Column\n",
    "\n",
    "# regex to find dates\n",
    "p = re.compile(r\"[\\d]{1,2}/[\\d]{1,2}/[\\d]{2,4}\")\n",
    "\n",
    "# function to extract dates and deal with NaT entries\n",
    "\n",
    "def date_fixer(column: pd.Series) -> list:\n",
    "    returned_dates = []\n",
    "    for date in column:\n",
    "        if isinstance(date, dt.datetime):\n",
    "            if pd.isnull(date) is False:\n",
    "                converted_date = pd.to_datetime(date)\n",
    "                returned_dates.append(converted_date)\n",
    "                last_recorded_date = converted_date\n",
    "            else: # pd.isnull(date) is True\n",
    "                returned_dates.append(last_recorded_date)\n",
    "        elif pd.isnull(date) is True:\n",
    "            returned_dates.append(last_recorded_date)\n",
    "        elif isinstance(date, str):\n",
    "            m = p.search(date)\n",
    "            if m:\n",
    "                converted_date = pd.to_datetime(m.group(), dayfirst=True)\n",
    "                returned_dates.append(converted_date)\n",
    "                last_recorded_date = converted_date\n",
    "            else:\n",
    "                returned_dates.append(last_recorded_date)\n",
    "        else:\n",
    "            returned_dates.append(last_recorded_date)\n",
    "    return returned_dates\n",
    "\n",
    "proper_dates = date_fixer(df[\"Date\"])\n",
    "\n",
    "proper_dates = pd.Series(proper_dates)\n",
    "\n",
    "print(proper_dates.shape)\n",
    "print(proper_dates.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c44437d-0601-49f0-b54c-4f4f85e8b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One time has been read as a time. Converting it to string to avoid changing function below\n",
    "# problem time\n",
    "print(df.iloc[43,1])\n",
    "# fixing issue\n",
    "df.iloc[43,1]=\"*0000\"\n",
    "# print corrected data\n",
    "print(df.iloc[43,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96652ea-c52b-4a43-80fa-8408e561601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time\n",
    "\n",
    "# function to add time data to new_date and set timezone to Australia\n",
    "\n",
    "def add_time(time: str, date: pd.Timestamp) -> pd.Timestamp:\n",
    "    # regex to find times \n",
    "    p = re.compile(r\"[\\d]{1,2}[\\d]{1,2}\")\n",
    "    match = p.search(time)\n",
    "    match_text = match.group()\n",
    "    # find matches and get hour and minute data\n",
    "    if len(match_text) == 3:\n",
    "        hour = int(match_text[0])\n",
    "        minute = int(match_text[1:3])\n",
    "    elif len(match_text) == 4:\n",
    "        hour = int(match_text[0:2])\n",
    "        minute = int(match_text[2:4])\n",
    "    else:\n",
    "        raise ValueError(\"Did not find match\")\n",
    "    # get date and replace with new time\n",
    "    date_time = date.replace(hour=hour, minute=minute)\n",
    "    return date_time\n",
    "\n",
    "time_strings = df[\"Time\"].astype(str)\n",
    "\n",
    "dates_times = pd.Series(map(add_time, time_strings, proper_dates))\n",
    "\n",
    "dates_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a57dc-fa39-4053-83fa-6033bbd03b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed\n",
    "\n",
    "def feed(recorded_data) -> str:\n",
    "    if pd.isna(recorded_data):\n",
    "        return None\n",
    "    else:\n",
    "        return \"Feed\"\n",
    "\n",
    "Feeds = pd.Series(map(bottle_feed, df[\"Feed\"]))\n",
    "\n",
    "Feeds_dummies = pd.get_dummies(Bottles)\n",
    "\n",
    "Feeds_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dbdfbb-e4a8-4293-866e-bea1a5ccfec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Poo column\n",
    "\n",
    "# Check data\n",
    "# If NA print how many instances\n",
    "print(f\"Numer of NA values: {df[df[\"Poo\"].isna()].shape[0]}\")\n",
    "\n",
    "# Get all unique values\n",
    "print(f\"Unique values are: {[val for val in df[\"Poo\"].unique()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02621b57-5429-47ae-9fda-cbc86f5005aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix NA values and normalise\n",
    "df[\"Poo\"].fillna(\"No\", inplace=True)\n",
    "\n",
    "# create normalised Series using match statement and map\n",
    "def poo_fixer(poo: str) -> str:\n",
    "    match poo:\n",
    "        case \"Yes\":\n",
    "            return \"Poo\"\n",
    "        case \"Yes \":\n",
    "            return \"Poo\"\n",
    "        case \"yes\":\n",
    "            return \"Poo\"\n",
    "        case \"Tiny amount\":\n",
    "            return \"Poo\"\n",
    "        case \"No\":\n",
    "            return None\n",
    "        case \"No \":\n",
    "            return None\n",
    "        case \"Small\":\n",
    "            return \"Poo\"\n",
    "        case \" No\":\n",
    "            return None\n",
    "        case \"no \":\n",
    "            return None\n",
    "        case \" \":\n",
    "            return None\n",
    "\n",
    "fixed_poos = pd.Series(map(poo_fixer, df[\"Poo\"]))\n",
    "\n",
    "fixed_poos = pd.get_dummies(new_poos)\n",
    "\n",
    "fixed_poos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d7176-abf6-49f9-adf3-5b4254d841c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wee Column\n",
    "\n",
    "# Check data\n",
    "# If NA print how many instances\n",
    "print(f\"Numer of NA values: {df[df[\"Wee\"].isna()].shape[0]}\")\n",
    "\n",
    "# Get all unique values\n",
    "print(f\"Unique values are: {[val for val in df[\"Wee\"].unique()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27609faa-9e6f-4654-9309-b06809db9813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix NA values and normalise\n",
    "df[\"Wee\"].fillna(\"No\", inplace=True)\n",
    "\n",
    "# create normalised Series using match statement and map\n",
    "def wee_fixer(wee: str) -> str:\n",
    "    match wee:\n",
    "        case \"Yes\":\n",
    "            return \"Wee\"\n",
    "        case \"Yes \":\n",
    "            return \"Wee\"\n",
    "        case \"Yea\":\n",
    "            return \"Wee\"\n",
    "        case \"yes\":\n",
    "            return \"Wee\"\n",
    "        case \"Yrs\":\n",
    "            return \"Wee\"\n",
    "        case \"No\":\n",
    "            return None\n",
    "\n",
    "fixed_wees = pd.Series(map(wee_fixer, df[\"Wee\"]))\n",
    "\n",
    "fixed_wees = pd.get_dummies(new_wees)\n",
    "\n",
    "fixed_wees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c32f5a-8d94-44e9-80b7-8f616d3988b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Vomits\n",
    "\n",
    "# Use regex to find 'vomit' matches\n",
    "def vomit_finder(note: str) -> str:\n",
    "    if isinstance(note, str):\n",
    "        p = re.compile(r\"vomit\", flags=re.I)\n",
    "        m = p.search(note)\n",
    "        if m:\n",
    "            return \"vomited\"\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        None\n",
    "\n",
    "vomits = pd.Series(map(vomit_finder, df[\"Other\"]))\n",
    "\n",
    "vomits = pd.get_dummies(vomits)\n",
    "\n",
    "vomits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab5c32-7e57-43f9-b418-f3b56c78b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stitch dataframe together\n",
    "\n",
    "data = {\"DateTime\": dates_times,\n",
    "        \"Feed\": Bottle_dummies[\"Bottle\"],\n",
    "        \"Poo\": new_poos[\"Poo\"],\n",
    "        \"Wee\": new_wees[\"Wee\"],\n",
    "        \"Vomit\": vomits[\"vomited\"]}\n",
    "\n",
    "df_clean_data = pd.DataFrame(data=data)\n",
    "\n",
    "df_clean_data.set_index(\"DateTime\", inplace=True)\n",
    "\n",
    "df_clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c7929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85993099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9104d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new cleanded dataset\n",
    "df_clean_data.to_csv(\"../Data/dataLeon.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
